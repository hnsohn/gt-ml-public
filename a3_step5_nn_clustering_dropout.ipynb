{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a062cd-323a-4ace-9812-9a0d3808d77c",
   "metadata": {},
   "source": [
    "## CS 7641 Machine Learning\n",
    "## Assignment 3 Unsupervised Learning and Dimensional Deduction\n",
    "#### Experiment: Step 5 Neural Network & Clustering\n",
    "#### Algorithms: KMeans, EM (GaurssianMixture)\n",
    "#### Data      : Dropout (Step4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c03b0dd-47b0-4ead-b775-6031e3fbdc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from scipy.stats import kurtosis \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from yellowbrick.cluster import InterclusterDistance\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "#from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677e992-97d3-41aa-ae31-46277f372636",
   "metadata": {},
   "source": [
    "## Predict Students' Dropout and Academic Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f5548c6-71dc-455d-8d0c-863208d9225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Data Load\n",
    "##\n",
    "\n",
    "df = pd.read_csv(\"./data/dropout.csv\", sep=\";\")\n",
    "\n",
    "# Target 데이터 분석 및 제거\n",
    "num_droupout = df.query('Target==\"Dropout\"')\n",
    "num_enrolled = df.query('Target==\"Enrolled\"')\n",
    "num_graduated = df.query('Target==\"Graduate\"')\n",
    "\n",
    "# Enrolled 데이타 삭제 (pending)\n",
    "df = df.drop(df[df['Target'] == \"Enrolled\"].index)\n",
    "\n",
    "# pandas dataframe replace (from https://heytech.tistory.com/441)\n",
    "df[\"Target\"].replace({'Dropout':0, 'Graduate':1}, inplace = True)\n",
    "\n",
    "X_raw = df.values[:,:-1]\n",
    "y_raw = df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34288a1b-8a09-4b3e-b5f0-71af3939d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to train one model\n",
    "def model_train(model, X_train, y_train, X_val, y_val, n_epochs = 100, lr=0.001):\n",
    "#def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=lr)  # modified \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)  # modified \n",
    " \n",
    "    #n_epochs = 300   # number of epochs to run\n",
    "    #n_epochs = n_epochs   # number of epochs to run # modified\n",
    "    n_epochs = 100   # number of epochs to run # modified\n",
    "    batch_size = 10  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    " \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    # restore model and return best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512dd04-5d18-4d8c-b306-d94531998573",
   "metadata": {},
   "source": [
    "## Neural Network + KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646b83f2-c929-4bb3-9cab-409d14322bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3630, 36)\n",
      "(3630, 9)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## KMeans\n",
    "##\n",
    "\n",
    "num_clusters = 9\n",
    "\n",
    "model = SparseRandomProjection(n_components=num_clusters, random_state=0)\n",
    "X_raw_rp = model.fit_transform(X_raw)\n",
    "\n",
    "print(X_raw.shape)\n",
    "print(X_raw_rp.shape)\n",
    "\n",
    "model = KMeans(n_clusters = 2, random_state = 0, n_init = 'auto')\n",
    "model.fit(X_raw_rp)\n",
    "y_pred = model.predict(X_raw_rp)\n",
    "\n",
    "X_raw_tensor = torch.tensor(X_raw_rp, dtype=torch.float32)\n",
    "y_raw_tensor = torch.tensor(y_pred, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw_tensor, y_raw_tensor, stratify=y_raw_tensor, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf472a7a-a238-43f5-9c42-6131d2af9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "## Neural Network + Kmeans\n",
    "##\n",
    "\n",
    "class Model (nn.Module):\n",
    "    def __init__(self, x):      \n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(9, x)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(x, x)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(x, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc11c8d6-52eb-4ec9-b794-d5a4b5f33350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time:  56.58988358301576\n",
      "Cross Validation Score: 0.9314623951911927\n",
      "Test Accuracy: 0.90633608815427\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_scores  = []\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for train, validate in kfold.split(X_train, y_train):\n",
    "    model = Model(36)\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[validate], y_train[validate], 100, 0.001)\n",
    "    cv_scores.append(acc)\n",
    "training_time = time.perf_counter() - start_time\n",
    "print(\"Training Time: \", training_time)\n",
    "\n",
    "acc_mean = np.mean(cv_scores)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    \n",
    "acc_test = metrics.accuracy_score(y_test.numpy(), np.rint(y_pred.numpy()))    \n",
    "\n",
    "print(\"Cross Validation Score: \" + str(acc_mean))\n",
    "print(\"Test Accuracy: \" + str(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe7c15-b7c9-4424-ac76-1305be3fc4e0",
   "metadata": {},
   "source": [
    "## Neural Network + EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eaace9d-8d2d-4212-8b52-5276e8a51343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3630, 36)\n",
      "(3630, 9)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## EM\n",
    "##\n",
    "\n",
    "num_clusters = 9\n",
    "\n",
    "model = SparseRandomProjection(n_components=num_clusters, random_state=0)\n",
    "X_raw_rp = model.fit_transform(X_raw)\n",
    "\n",
    "print(X_raw.shape)\n",
    "print(X_raw_rp.shape)\n",
    "\n",
    "model = GaussianMixture(n_components = 2)\n",
    "model.fit(X_raw_rp)\n",
    "y_pred = model.predict(X_raw_rp)\n",
    "\n",
    "X_raw_tensor = torch.tensor(X_raw_rp, dtype=torch.float32)\n",
    "y_raw_tensor = torch.tensor(y_pred, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw_tensor, y_raw_tensor, stratify=y_raw_tensor, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aafe1f2-81e3-4220-b08c-0d5bb1889780",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "## Neural Network + Kmeans\n",
    "##\n",
    "\n",
    "class Model (nn.Module):\n",
    "    def __init__(self, x):      \n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(9, x)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(x, x)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(x, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92cf1176-387b-4368-a981-7d6ba0e6ad0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time:  59.30186904093716\n",
      "Cross Validation Score: 0.9721093297004699\n",
      "Test Accuracy: 0.9614325068870524\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_scores  = []\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for train, validate in kfold.split(X_train, y_train):\n",
    "    model = Model(36)\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[validate], y_train[validate], 100, 0.001)\n",
    "    cv_scores.append(acc)\n",
    "training_time = time.perf_counter() - start_time\n",
    "print(\"Training Time: \", training_time)\n",
    "\n",
    "acc_mean = np.mean(cv_scores)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    \n",
    "acc_test = metrics.accuracy_score(y_test.numpy(), np.rint(y_pred.numpy()))    \n",
    "\n",
    "print(\"Cross Validation Score: \" + str(acc_mean))\n",
    "print(\"Test Accuracy: \" + str(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2353cb-b78a-4b31-b6ca-2058517d0f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
